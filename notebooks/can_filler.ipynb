{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrair e tratar dados da planilha de respostas do fornecedor #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(file_path, sheet_name, column_letters):\n",
    "    \"\"\"\n",
    "    Extracts data from specific columns in an Excel sheet.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input Excel file.\n",
    "        sheet_name (str): Name of the sheet to extract data from.\n",
    "        column_letters (list of str): List of column letters to extract data from.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the extracted data with column names from row 15.\n",
    "    \"\"\"\n",
    "    # Load workbook and sheet\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "    sheet = wb[sheet_name]\n",
    "\n",
    "    # Read column names from row 15\n",
    "    column_names = [sheet[f'{col}15'].value for col in column_letters]\n",
    "\n",
    "    # Initialize a dictionary to store the data\n",
    "    data = {col: [] for col in column_names}\n",
    "\n",
    "    # Extract values from each column, ignoring the first 13 cells and row 15\n",
    "    for col_letter, column_name in zip(column_letters, column_names):\n",
    "        column_data = [cell.value for cell in sheet[col_letter] if cell.row > 13]\n",
    "        # Add data to the corresponding list\n",
    "        data[column_name] = column_data\n",
    "\n",
    "    # Find the maximum length of the lists\n",
    "    max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "    # Standardize the length of the lists with missing values (None)\n",
    "    for key in data:\n",
    "        while len(data[key]) < max_length:\n",
    "            data[key].append(None)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planilhas a serem extraídas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_khs = '../files/KHS.xlsx'\n",
    "file_path_krones = '../files/KRONES.xlsx'\n",
    "file_path_sidel = '../files/SIDEL.xlsx'\n",
    "sheet_filler = 'CAN Filler'\n",
    "column_filler = ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seções Can Filler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_filler_sections = {\n",
    "    \"1.0 PERFORMANCE and WARRANTY\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"2.0 GENERAL INFORMATION\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"3.0 PROCESS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"4.0 CONSTRUCTIVE CHARACTERISTICS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"5.0 FILLER ACCESSORIES\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"6.0 DIMENSIONS / WEIGHT\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"7.0 OXYGEN ELIMINATORS DEVICES\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"8.0 MATERIALS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"9.0 CHANGE OVER\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"10.0 SAFETY\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"11.0 ELECTRICITY, CONTROL, ALARM, AUTOMATION\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"12.0 POWER CABINETS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"13.0 UTILITIES CONSUMPTION\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"14.0 MAINTENANCE / DOCUMENTATION / TRAINING\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"15.0 TEC CAN FILLER ACCEPTANCE\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"16.0 ZONE DEMANDS DUE TO LOCAL REGULATIONS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    },\n",
    "    \"17.0 HISTORY OF REVISIONS\": {\n",
    "        \"start\": \"\",\n",
    "        \"end\": \"\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificar os índices das seções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_section(item):\n",
    "    return isinstance(item, str) and item in can_filler_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_index(df):\n",
    "    section_indexes = df[df['ITEM'].apply(is_section)].index.tolist()\n",
    "    section_indexes.append(len(df))  # adiciona o índice do final do DataFrame\n",
    "    return section_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indexes(df, indexes, sections_dict):\n",
    "    for i in range(len(indexes) - 1):\n",
    "        start_idx = indexes[i]\n",
    "        end_idx = indexes[i + 1]\n",
    "        section_name = df.loc[start_idx, 'ITEM']\n",
    "        sections_dict[section_name][\"start\"] = start_idx + 1 \n",
    "        sections_dict[section_name][\"end\"] = end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar planilhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df(df_supplier, sections, section_name):\n",
    "    df = df_supplier.iloc[sections[section_name]['start']:sections[section_name]['end']].reset_index(drop=True).rename(columns={'CNV': 'Charachteristic', 'UNIT': 'Instruction/Comments'}).drop(index=0, columns=['ITEM', 'ITEM DESCRIPTION', 'INDEX', 'Instruction / Comments', None])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df_performance(df_supplier, sections, section_name):\n",
    "    df = df_supplier.iloc[sections[section_name]['start']:sections[section_name]['end']].reset_index(drop=True).drop(index=[0], columns=['ITEM', None])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df_utilities(df_supplier, sections, section_name):\n",
    "    df = df_supplier.iloc[sections[section_name]['start']:sections[section_name]['end']].reset_index(drop=True).drop(index=[0], columns=['ITEM', 'ITEM DESCRIPTION', 'Instruction / Comments']).rename(columns={'CNV': 'Characteristic', 'INDEX': 'Instruction / Comments'}).dropna(subset=['Characteristic'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df_maintenance(df_supplier, sections, section_name):\n",
    "    df = df_supplier.iloc[sections[section_name]['start']:sections[section_name]['end']].reset_index(drop=True).drop(index=[0], columns=['ITEM', 'INDEX', 'ITEM DESCRIPTION', 'Instruction / Comments']).rename(columns={'CNV': 'Characteristic', 'UNIT': 'Instruction', None: 'Comments'}).dropna(subset=['Characteristic'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_df_zone(df_supplier, sections, section_name):\n",
    "    df = df_supplier.iloc[sections[section_name]['start']:sections[section_name]['end']].reset_index(drop=True).drop(index=[0], columns=['ITEM', 'UNIT', 'INDEX']).rename(columns={'CNV': 'Zone', 'ITEM DESCRIPTION': 'Detail','Instruction / Comments': 'Instruction', None: 'Comments'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KHS: # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_khs = extract_info(file_path=file_path_khs, sheet_name=sheet_filler, column_letters=column_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_khs.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0 PERFORMANCE and WARRANTY': {'start': 1, 'end': 29},\n",
       " '2.0 GENERAL INFORMATION': {'start': 30, 'end': 40},\n",
       " '3.0 PROCESS': {'start': 41, 'end': 71},\n",
       " '4.0 CONSTRUCTIVE CHARACTERISTICS': {'start': 72, 'end': 91},\n",
       " '5.0 FILLER ACCESSORIES': {'start': 92, 'end': 139},\n",
       " '6.0 DIMENSIONS / WEIGHT': {'start': 140, 'end': 149},\n",
       " '7.0 OXYGEN ELIMINATORS DEVICES': {'start': 150, 'end': 154},\n",
       " '8.0 MATERIALS': {'start': 155, 'end': 181},\n",
       " '9.0 CHANGE OVER': {'start': 182, 'end': 187},\n",
       " '10.0 SAFETY': {'start': 188, 'end': 197},\n",
       " '11.0 ELECTRICITY, CONTROL, ALARM, AUTOMATION': {'start': 198, 'end': 233},\n",
       " '12.0 POWER CABINETS': {'start': 234, 'end': 246},\n",
       " '13.0 UTILITIES CONSUMPTION': {'start': 247, 'end': 263},\n",
       " '14.0 MAINTENANCE / DOCUMENTATION / TRAINING': {'start': 264, 'end': 290},\n",
       " '15.0 TEC CAN FILLER ACCEPTANCE': {'start': 291, 'end': 293},\n",
       " '16.0 ZONE DEMANDS DUE TO LOCAL REGULATIONS': {'start': 294, 'end': 319},\n",
       " '17.0 HISTORY OF REVISIONS': {'start': 320, 'end': 330}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khs_indexes = get_section_index(df_khs)\n",
    "_ = add_indexes(df_khs, khs_indexes, can_filler_sections)\n",
    "can_filler_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planilhas separadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = separate_df_performance(df_khs, can_filler_sections, \"1.0 PERFORMANCE and WARRANTY\")\n",
    "df_general_info = separate_df(df_khs, can_filler_sections, \"2.0 GENERAL INFORMATION\")\n",
    "df_process = separate_df(df_khs, can_filler_sections, \"3.0 PROCESS\")\n",
    "df_characteristics = separate_df(df_khs, can_filler_sections, \"4.0 CONSTRUCTIVE CHARACTERISTICS\")\n",
    "df_accessories = separate_df(df_khs, can_filler_sections, \"5.0 FILLER ACCESSORIES\")\n",
    "df_dimensions = separate_df(df_khs, can_filler_sections, \"6.0 DIMENSIONS / WEIGHT\")\n",
    "df_oxygen = separate_df(df_khs, can_filler_sections, \"7.0 OXYGEN ELIMINATORS DEVICES\")\n",
    "df_materials = separate_df(df_khs, can_filler_sections, \"8.0 MATERIALS\")\n",
    "df_change = separate_df(df_khs, can_filler_sections, \"9.0 CHANGE OVER\")\n",
    "df_safety = separate_df(df_khs, can_filler_sections, \"10.0 SAFETY\")\n",
    "df_electricity = separate_df(df_khs, can_filler_sections, \"11.0 ELECTRICITY, CONTROL, ALARM, AUTOMATION\")\n",
    "df_power = separate_df(df_khs, can_filler_sections, \"12.0 POWER CABINETS\")\n",
    "df_utilities = separate_df_utilities(df_khs, can_filler_sections, \"13.0 UTILITIES CONSUMPTION\")\n",
    "df_maintenance = separate_df_maintenance(df_khs, can_filler_sections, \"14.0 MAINTENANCE / DOCUMENTATION / TRAINING\")\n",
    "df_acceptance = separate_df(df_khs, can_filler_sections, \"15.0 TEC CAN FILLER ACCEPTANCE\")\n",
    "df_zone = separate_df_zone(df_khs, can_filler_sections, \"16.0 ZONE DEMANDS DUE TO LOCAL REGULATIONS\")\n",
    "\n",
    "dataframes = [\n",
    "    df_performance,\n",
    "    df_general_info,\n",
    "    df_process,\n",
    "    df_characteristics,\n",
    "    df_accessories,\n",
    "    df_dimensions,\n",
    "    df_oxygen,\n",
    "    df_materials,\n",
    "    df_change,\n",
    "    df_safety,\n",
    "    df_electricity,\n",
    "    df_power,\n",
    "    df_utilities,\n",
    "    df_maintenance,\n",
    "    df_acceptance,\n",
    "    df_zone\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chamar o LLM #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "            azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "            deployment_name = os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "            api_version = \"2023-09-01-preview\",\n",
    "            temperature = 0.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You are an expert at selecting suppliers that will provide equipments to the company you work for.\n",
    "    The suppliers fill a spreadsheet with their machines' specifications and based on that, you check if the answers correspond to what your company requires to make them an official supplier.\n",
    "\n",
    "    In this task, you will analyze this data:\n",
    "    \n",
    "    ```\n",
    "    {df_data}\n",
    "    ```\n",
    "\n",
    "    For each JSON object, you will check if the supplier's answer can fill the requirements according to the other fields.\n",
    "    The CNV field describes what is being analyzed, in case you need more information.\n",
    "\n",
    "    GUIDELINES:\n",
    "    - For each JSON object, you should add another field called \"COMMENT\" and it should only contain \"OK\" or \"NOK\". \"OK\" in case the supplier's answer can fill the requirement or \"NOK\" in case the supplier's answer does not fill the requirement.\n",
    "    - For each JSON object, you should add another field called \"REASON\", and it should contain the reason for you to label the answer as \"OK\" or \"NOK\".\n",
    "    - Your response should only contain a valid JSON with the analysis made.\n",
    "    - If there's not enough information to make the analysis, in the field \"COMMENT\" just write \"Not enough information\".\n",
    "    - Don't evaluate the suppliers answers if you don't know if they fill the requirements.\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
